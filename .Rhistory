a1_counts <- as.matrix(a1_counts)
mode(a1_counts) <- "integer"
#a1_sub <- a1_counts[rownames(a1_counts) %in% rownames(estimates),]
tot_counts <- as.matrix(tot_counts)
mode(tot_counts) <- "integer"
mu_alt
theta_alt
theta_alt <- as.list(estimates_group[[k]]$bb_theta)
names(theta_alt) <- as.list(estimates_group[[k]]$group)
ind3 <- match(names(groups), names(mean_alt))
mean_alt <- as.list(estimates_group[[k]]$mean_smoothed)
#adding names to control for the missing values
names(mean_alt) <- as.list(estimates_group[[k]]$group)
theta_alt <- as.list(estimates_group[[k]]$bb_theta)
names(theta_alt) <- as.list(estimates_group[[k]]$group)
ind3 <- match(names(groups), names(mean_alt))
mean_alt <- mean_alt[ind3]
ind4 <- match(names(groups), names(theta_alt))
theta_alt <- theta_alt[ind4]
theta_alt
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
y <-  a1_counts[k,]
n <- tot_counts[k,]
a2 <- n - y
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
View(df)
df_split <- lapply(groups, function(q) df[rownames(df) %in% rownames(q),])
View(df_split)
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_alt.lik
mu_alt
theta_alt
disp_ge_alt.lik
lbetabin <- function(df, inits){
y <- df[,1]
n <- df[,2]
alpha = inits[1]
beta = inits[2]
sum(lchoose(n, y) + lgamma(alpha+beta) - lgamma(n+alpha+beta) +
lgamma(y+alpha) - lgamma(alpha) + lgamma(n-y+beta) - lgamma(beta))
}
#beta-binomial log likelihood function
lbetabin <- function(df, mu, theta){
min_theta = 1e-06
max_mu = 0.999999
min_mu = 1e-06
theta <- pmax(theta, min_theta)
mu <- pmin(mu, max_mu)
mu <- pmax(mu, min_mu)
y <- df[,1]
n <- df[,2]
alpha <- mu/theta
beta <- (1-mu)/theta
sum(lchoose(n, y) + lgamma(alpha+beta) - lgamma(n+alpha+beta) +
lgamma(y+alpha) - lgamma(alpha) + lgamma(n-y+beta) - lgamma(beta))
}
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_llr = mapply(function(p,q) p - q, disp_ge_null.lik, disp_ge_alt.lik, SIMPLIFY = F)
#replacing null element with NA
#disp_ge_llr <- lapply(disp_ge_llr, function(q) ifelse(is.null(q), NA, q))
disp_ge_llr
disp_ge_llr_vec[k,] <-  do.call("c", disp_ge_llr)
do.call("c", disp_ge_llr)
dim(disp_ge_llr_vec)
allelicSwitch <- function(a1_counts, tot_counts, metadata, split.var = "group", min_counts = 0, min_cells = 5, estimates, estimates_group){
are_equal(dim(a1_counts), dim(tot_counts),
msg = paste("allele 1 and total counts matrices must be equal"))
are_equal(rownames(a1_counts), rownames(tot_counts),
msg = paste("allele 1 and total counts matrices must be in the same order"))
are_equal(rownames(a1_counts), rownames(estimates),
msg = paste("gene order in the count matrices and the parameter estimates must be the same"))
are_equal(rownames(estimates), names(estimates_group),
msg = paste("gene order in the global and group parameter estimates must be the same"))
#beta-binomial log likelihood function
lbetabin <- function(df, mu, theta){
min_theta = 1e-06
max_mu = 0.999999
min_mu = 1e-06
theta <- pmax(theta, min_theta)
mu <- pmin(mu, max_mu)
mu <- pmax(mu, min_mu)
y <- df[,1]
n <- df[,2]
alpha <- mu/theta
beta <- (1-mu)/theta
sum(lchoose(n, y) + lgamma(alpha+beta) - lgamma(n+alpha+beta) +
lgamma(y+alpha) - lgamma(alpha) + lgamma(n-y+beta) - lgamma(beta))
}
# A function to rbind the data frames in the list, leaving out one at a time
rbind_consec <- function(df_list, idx) {
df_to_rbind <- df_list[-idx]  # Leave out the data frame at the specified index
do.call(rbind, df_to_rbind)  # Use do.call to rbind all data frames in the list
}
a1_counts <- as.matrix(a1_counts)
mode(a1_counts) <- "integer"
#a1_sub <- a1_counts[rownames(a1_counts) %in% rownames(estimates),]
tot_counts <- as.matrix(tot_counts)
mode(tot_counts) <- "integer"
#tot_sub <- tot_counts[rownames(tot_counts) %in% rownames(estimates),]
groups <- split(metadata, f = metadata[,colnames(metadata) == split.var])
len <- dim(a1_counts)[1]
alpha <- beta <- loglik0  <- loglik1 <- llr <- pval <- loglik0_adj <- loglik1_adj <- llr_adj <- pval_adj <- AR <-  log2FC <- N <- tot_gene_mean <- mu <- var <-
loglik0_var <- loglik1_var <- llr_var <- pval_var <- theta_global <- mu_global <- numeric(len)
loglik_group <- alpha_group <- beta_group <- mu_group <- theta_group <- theta_fit <- var_group <- var_null_group <- var_alt_group <- llr_imb <- pval_imb <- llr_oneout_group <- pval_oneout_group <-
llr_imb <- pval_imb <- llr_imb_adj <- pval_imb_adj <- theta_fit_ciupper <- theta_fit_cilower <- chisq_group <- within_ci <-
disp_ge_pval_vec <- disp_ge_llr_vec <- matrix(nrow = len, ncol = length(groups))
for  (k in 1:nrow(a1_counts)) {
y <-  a1_counts[k,]
n <- tot_counts[k,]
a2 <- n - y
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
log2FC[k] = log2(mean(y)) - log2(mean(a2))
AR[k] = mean(y/n, na.rm = T)
N[k] = dim(df[df$n >= 5,])[1]
tot_gene_mean[k] = mean(df$n)
if (N[k] >= min_cells){
df_split <- lapply(groups, function(q) df[rownames(df) %in% rownames(q),])
mu <- estimates[k, "bb_mu"]
theta <- estimates[k, "bb_theta"]
theta_adj <- estimates[k, "thetaCorrected"]
theta_common <- estimates[k, "theta_common"]
#########################################
# Test for changes in mean AR over time #
#########################################
#Null hypothesis: assumes no changes between time points
#bb_mu is common mean AR (estimated across cells)
#bb_theta is shrunk theta (across all cells)
nul.lik <- tryCatch(lbetabin(df, mu = mu, theta = theta_adj), error=function(e) NA)
loglik0[k] = nul.lik
#Alternative hypothesis
#bb_mu is mean AR estimated separately for each time point
#bb_theta is shrunk theta in each time point
mu_alt <- as.list(estimates_group[[k]]$bb_mu)
theta_adj_group <- as.list(estimates_group[[k]]$thetaCorrected)
#adding names to the values in order to match the appropriate mu and dispersion estimates
#to the correct group
names(mu_alt) <- as.list(estimates_group[[k]]$group)
names(theta_adj_group) <- as.list(estimates_group[[k]]$group)
ind1 <- match(names(groups), names(theta_adj_group))
mu_alt <- mu_alt[ind1]
ind2 <- match(names(groups), names(theta_adj_group))
theta_adj_group <- theta_adj_group[ind2]
#replacing null element with NA
mu_alt <- lapply(mu_alt, function(q) ifelse(is.null(q), NA, q))
theta_adj_group <- lapply(theta_adj_group, function(q) ifelse(is.null(q), NA, q))
#calculating group likelihood values
alt.lik <- list()
for (i in 1:length(groups)){
alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_adj_group[names(groups)[i]][[1]]), error = function(e) NA)
}
#calculating group-wise likelihood
loglik1[k] = do.call("sum", c(alt.lik, na.rm = T))
llr[k] = loglik0[k] - loglik1[k]
pval[k] <- pchisq(-2*(llr[k]), df = 1, lower.tail = FALSE)
#test for mean equality between the groups whilst keeping theta constant
#to identify changes in the allelic ratio that are due to the changes in mean rather than varince
#theta_null <- theta_common
#mean.nul.lik <- tryCatch(lbetabin(df, mu = mu, theta = theta_null), error=function(e) NA)
#loglik0_mean[k] = mean.nul.lik
#Calculating group-wise likelihoods
#theta_group_null <- as.list(estimates_group[[k]]$theta_common)
#adding names to control for the missing values
#names(theta_group_null) <- as.list(estimates_group[[k]]$group)
#ind2 <- match(names(groups), names(theta_group_null))
#theta_group_null <- theta_group_null[ind2]
#calculating group likelihood values
#alt_mean.lik <- list()
#for (i in 1:length(groups)){
#  alt_mean.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
#                                         mu = mu_alt[names(groups)[i]][[1]],
#                                         theta = theta_group_null[names(groups)[i]][[1]]), error = function(e) NA)
#}
#calculating group-wise likelihood
#loglik1_mean[k] = do.call("sum", alt_mean.lik)
#llr_mean[k] = loglik0_mean[k] - loglik1_mean[k]
#pval_mean[k] <- pchisq(-2*(llr_mean[k]), df = 1, lower.tail = FALSE)
#replace null values with NA
#theta_group_null <- lapply(theta_group_null, function (q) ifelse(is.null(q), NA, q))
#names(theta_group_null) <- as.list(estimates_group[[k]]$group)
#theta_fit[k,] <- do.call("c", theta_group_null)
##############################################################################
# Test for variance equality between the groups whilst keeping mean constant #
##############################################################################
#to identify changes in allelic ratio over pseudotime that are due to the variance rather than mean
#allelic ratio is fixed - locfit regression where mean AR is fitted against the total counts
#Null hypothesis:
#bb_mu is a mean predicted from locfit function (fit across all cells)
#bb_theta is the original dispersion estimate
mean_null <- estimates[k, "mean_smoothed"]
var.nul.lik <- tryCatch(lbetabin(df, mu = mean_null, theta = theta), error=function(e) NA)
loglik0_var[k] = var.nul.lik
#Alternative hypothesis:
#bb_mu is mean predicted from the local regression (fit separately for each time point)
#bb_theta is the original dispersion (estimated for each time point)
mean_alt <- as.list(estimates_group[[k]]$mean_smoothed)
#adding names to control for the missing values
names(mean_alt) <- as.list(estimates_group[[k]]$group)
theta_alt <- as.list(estimates_group[[k]]$bb_theta)
names(theta_alt) <- as.list(estimates_group[[k]]$group)
ind3 <- match(names(groups), names(mean_alt))
mean_alt <- mean_alt[ind3]
ind4 <- match(names(groups), names(theta_alt))
theta_alt <- theta_alt[ind4]
#replacing null element with NA
mean_alt <- lapply(mean_alt, function(q) ifelse(is.null(q), NA, q))
theta_alt <- lapply(theta_alt, function(q) ifelse(is.null(q), NA, q))
#calculating group likelihood values
alt_var.lik <- list()
for (i in 1:length(groups)){
alt_var.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mean_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
#calculating group-wise likelihood
loglik1_var[k] = do.call("sum", c(alt_var.lik, na.rm = T))
llr_var[k] = loglik0_var[k] - loglik1_var[k]
pval_var[k] <- pchisq(-2*(llr_var[k]), df = 1, lower.tail = FALSE)
############################################################
# comparing if variance in a specific time point different #
# from the expected for genes with similar expression      #
############################################################
#Null hypothesis:
#bb_mu is mean AR estimated for each time point
#bb_theta is predicted dispersion obtained from the local regression (fit across all cells)
theta_null <- theta_common
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_llr = mapply(function(p,q) p - q, disp_ge_null.lik, disp_ge_alt.lik, SIMPLIFY = F)
#replacing null element with NA
#disp_ge_llr <- lapply(disp_ge_llr, function(q) ifelse(is.null(q), NA, q))
disp_ge_llr_vec[k,] <-  do.call("c", disp_ge_llr)
disp_ge_pval <- lapply(disp_ge_llr, function(q) pchisq(-2*q, df = 1, lower.tail = FALSE))
disp_ge_pval_vec[k,] <-  do.call("c", disp_ge_pval)
mu_global[k] <- mu
theta_global[k] <- theta
theta_group[k,] <- do.call("c", theta_adj_group) #shrunk dispersion values per group
mu_group[k,] <- do.call("c", mu_alt) #mean AR values per group
} else {
mu_global[k] <- NA
theta_global[k] <- NA
loglik0[k] <- NA
loglik1[k] <- NA
llr[k] <- NA
pval[k] <- NA
loglik0_var[k] <- NA
loglik1_var[k] <- NA
llr_var[k] <- NA
pval_var[k] <- NA
}
}
#colnames(alpha_group) <- paste0("alpha_group", names(groups))
#colnames(beta_group) <- paste0("beta_group", names(groups))
colnames(mu_group) <- paste0("mu_group", names(groups))
colnames(theta_group) <- paste0("theta_group", names(groups))
#colnames(loglik_group) <- paste0("loglik_group", names(groups))
colnames(disp_ge_llr_vec) <- paste0("disp_ge_llr", names(groups))
colnames(disp_ge_pval_vec) <- paste0("disp_ge_pval", names(groups))
#colnames(mu_group) <- paste0("mu_group", names(groups))
#colnames(llr_var) <- paste0("llr_var", names(groups))
#colnames(pval_var) <- paste0("pval_var", names(groups))
out <- data.frame(cbind(#estimates,
N, tot_gene_mean, AR, log2FC, mu_global, theta_global, mu_group, theta_group,
loglik0, loglik1, llr, pval,
loglik0_var, loglik1_var, llr_var, pval_var,
disp_ge_llr_vec, disp_ge_pval_vec))
rownames(out) <- rownames(a1_counts)
out
}
pseudot_change <- allelicSwitch(Cast_B6_a1, Cast_B6_tot, min_cells = 5, metadata = pseudotime,  split.var = "group", estimates = global_shrunk, estimates_group = group_params_list)
devtools::document()
rm(list = c("allelicSwitch"))
devtools::document()
are_equal(dim(a1_counts), dim(tot_counts),
msg = paste("allele 1 and total counts matrices must be equal"))
assert_that(are_equal(dim(a1_counts), dim(tot_counts)),
msg = paste("allele 1 and total counts matrices must be equal"))
tot_counts <- tot_counts[-1,]
assert_that(are_equal(dim(a1_counts), dim(tot_counts)),
msg = paste("allele 1 and total counts matrices must be equal"))
are_equal(dim(a1_counts), dim(tot_counts),
msg = paste("allele 1 and total counts matrices must be equal"))
assert_that(are_equal(dim(metadata)[2], dim(tot_counts)[1]),
msg = paste("Number of cells in metadata and the count matrices must be the same"))
devtools::document()
devtools::install()
library(ASPEN)
library(pkgdown)
use_pkgdown_github_pages()
library(usethis)
use_pkgdown_github_pages()
?use_git
library(usethis)
?use_git
use_pkgdown_github_pages()
use_pkgdown_github_pages(new_process = TRUE)
use_pkgdown_github_pages(new_process == TRUE)
?use_pkgdown_github_pages
build_site()
library(pkgdown)
build_site()
#loading required libraries
library(ASPEN)
library(gridExtra)
library(openxlsx)
data("Cast_B6_a1")
data("Cast_B6_tot")
load_file <- system.file("extdata", "Cast_B6_cell_annot.xlsx", package = "ASPEN")
cell_annot <- read.xlsx(load_file, rowNames = T)
#loading pseudotime assignment
load_time <- system.file("extdata", "pseudotime_CastB6.xlsx", package = "ASPEN")
pseudotime <- read.xlsx(load_time, rowNames = T)
head(pseudotime)
Cast_B6_a1 <- Cast_B6_a1[,colnames(Cast_B6_a1) %in% pseudotime$cell_id]
Cast_B6_tot <- Cast_B6_tot[,colnames(Cast_B6_tot) %in% pseudotime$cell_id]
#Remove low-expressed genes which have less than 10 cells
Cast_B6_tot  <- Cast_B6_tot[rowSums(Cast_B6_tot > 1) >= 10,]
Cast_B6_a1  <- Cast_B6_a1[rownames(Cast_B6_tot),]
pseudotime <- pseudotime[match(colnames(Cast_B6_tot), pseudotime$cell_id),]
pseudotime$group <- cut(pseudotime$time, breaks=c(quantile(pseudotime$time, probs = seq(0, 1, by = 0.2))))
pseudotime$group[is.na(pseudotime$group)] <- levels(pseudotime$group)[1]
#adding cell ids to pseudotime obejct row names
rownames(pseudotime) <- pseudotime$cell_id
head(pseudotime)
group_params <- estim_bbparams_bygroup(Cast_B6_a1, Cast_B6_tot, metadata = pseudotime, split.var = "group", min_cells = 5, cores = 6)
dim(pseudotime)[2]
dim(metadata)
dim(pseudotime)
dim(tot_counts)
dim(Cast_B6_tot)
devtools::document()
devtools::install()
?usethis::use_pkgdown_github_pages
build_site()
pkgdown::build_site()
.Last.error
library(devtools)
install_github('r-lib/downlit')
library(downlit)
pack <- available.packages()
pack["pkgdown","Depends"]
pack["pkgdown","Imports"]
pack["pkgdown","Suggests"]
pack["evaluate","Version"]
pack["testthat","Version"]
pack["pkgload","Version"]
pack["callr","Version"]
pkgdown::clean_site()
pkgdown::clean_site()
pkgdown::clean_cache()
devtools::document()
devtools::document()
devtools::install()
pkgdown::build_site()
.Last.error
pkgdown::clean_cache()
pkgdown::build_site()
?build_site
pkgdown::build_site(examples = FALSE)
.Last.error
install.packages("evaluate")
install.packages("evaluate")
install.packages("evaluate")
pkgdown::build_site()
.Last.error
Sys.which("make")
getwd()
pkgdown::clean_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
.Last.error
pkgdown::build_articles()
pkgdown::clean_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
.Last.error
pkgdown::build_articles()
#loading required libraries
library(ASPEN)
library(gridExtra)
library(openxlsx)
data("Cast_B6_a1")
data("Cast_B6_tot")
load_file <- system.file("extdata", "Cast_B6_cell_annot.xlsx", package = "ASPEN")
cell_annot <- read.xlsx(load_file, rowNames = T)
table(cell_annot$cell_idents)
#splitting the metadata by cell type
cell_list <- split(cell_annot, f = cell_annot$cell_idents)
a1_mat <- lapply(cell_list, function(q) Cast_B6_a1[,gsub(".*_", "", colnames(Cast_B6_a1)) %in% q$cell_barcode_clean])
tot_mat <- lapply(cell_list, function(q) Cast_B6_tot[,gsub(".*_", "", colnames(Cast_B6_tot)) %in% q$cell_barcode_clean])
mapply(function(p, q) dim(p) == dim(q), a1_mat, tot_mat, SIMPLIFY = F)
mapply(function(p, q) table(rownames(p) == rownames(q)), a1_mat, tot_mat, SIMPLIFY = F)
#Remove low-expressed genes which have less than 10 cells
tot_mat  <- lapply(tot_mat, function(q) q[rowSums(q > 1) >= 10,])
a1_mat  <- mapply(function(p, q) p[rownames(q),],
a1_mat, tot_mat, SIMPLIFY = F)
bb_init_params <- mapply(function(p, q) estim_bbparams(p, q, min_cells = 5, cores = 6), a1_mat, tot_mat, SIMPLIFY = F)
bb_init_params <- mapply(function(p, q) estim_bbparams(p, q, min_cells = 5, cores = 6), a1_mat, tot_mat, SIMPLIFY = F)
devtools::document()
devtools::install()
library(ASPEN)
bb_init_params <- mapply(function(p, q) estim_bbparams(p, q, min_cells = 5, cores = 6), a1_mat, tot_mat, SIMPLIFY = F)
#loading required libraries
library(ASPEN)
library(gridExtra)
library(openxlsx)
data("Cast_B6_a1")
data("Cast_B6_tot")
load_file <- system.file("extdata", "Cast_B6_cell_annot.xlsx", package = "ASPEN")
cell_annot <- read.xlsx(load_file, rowNames = T)
#splitting the metadata by cell type
cell_list <- split(cell_annot, f = cell_annot$cell_idents)
a1_mat <- lapply(cell_list, function(q) Cast_B6_a1[,gsub(".*_", "", colnames(Cast_B6_a1)) %in% q$cell_barcode_clean])
tot_mat <- lapply(cell_list, function(q) Cast_B6_tot[,gsub(".*_", "", colnames(Cast_B6_tot)) %in% q$cell_barcode_clean])
#Remove low-expressed genes which have less than 10 cells
tot_mat  <- lapply(tot_mat, function(q) q[rowSums(q > 1) >= 10,])
a1_mat  <- mapply(function(p, q) p[rownames(q),],
a1_mat, tot_mat, SIMPLIFY = F)
dim(a1_mat)
lapply(a1_mat, dim)
View(a1_mat)
View(tot_mat)
head(gsub(".*_", "", colnames(Cast_B6_a1)))
View(cell_annot)
a1_mat <- lapply(cell_list, function(q) Cast_B6_a1[,gsub(".*_", "", colnames(Cast_B6_a1)) %in% q$cell_barcode])
tot_mat <- lapply(cell_list, function(q) Cast_B6_tot[,gsub(".*_", "", colnames(Cast_B6_tot)) %in% q$cell_barcode])
lapply(a1_mat, dim)
lapply(tot_mat, dim)
bb_init_params <- mapply(function(p, q) estim_bbparams(p, q, min_cells = 5, cores = 6), a1_mat, tot_mat, SIMPLIFY = F)
View(bb_init_params)
View(bb_init_params[["Cortical neurons"]])
set.seed(1001011)
shrink_pars <- lapply(bb_init_params, estim_delta)
View(shrink_pars)
bb_init_params <- lapply(bb_init_params, function(q) q[!is.na(q$theta_reestim),])
shrunk_estims_vardelta <- mapply(function(p, q) correct_theta(p, N_set = q[1], delta_set = q[2], thetaFilter = 0.001),
bb_init_params, shrink_pars, SIMPLIFY = F)
View(bb_init_params)
load_file <- system.file("extdata", "mm10_genesXY.txt", package = "ASPEN")
genesXY <- read.table(load_file)
load_file <- system.file("extdata", "mm10_imprinted_genes.xlsx", package = "ASPEN")
genesIMPR <- read.xlsx(load_file, colNames = T)
genes2remove <- c(genesXY$V1, genesIMPR$imprinted.genes)
View(genesXY)
View(bb_init_params)
View(bb_init_params)
devtools::document()
devtools::install()
devtools::document()
devtools::document()
devtools::install()
pkgdown::clean_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
usethis::use_pkgdown_github_pages()
pkgdown::use_pkgdown_github_pages()
usethis::use_pkgdown()
