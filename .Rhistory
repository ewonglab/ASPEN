mu <- estimates[k, "bb_mu"]
theta <- estimates[k, "bb_theta"]
theta_adj <- estimates[k, "thetaCorrected"]
theta_common <- estimates[k, "theta_common"]
#########################################
# Test for changes in mean AR over time #
#########################################
#Null hypothesis: assumes no changes between time points
#bb_mu is common mean AR (estimated across cells)
#bb_theta is shrunk theta (across all cells)
nul.lik <- tryCatch(lbetabin(df, mu = mu, theta = theta_adj), error=function(e) NA)
loglik0[k] = nul.lik
#Alternative hypothesis
#bb_mu is mean AR estimated separately for each time point
#bb_theta is shrunk theta in each time point
mu_alt <- as.list(estimates_group[[k]]$bb_mu)
theta_adj_group <- as.list(estimates_group[[k]]$thetaCorrected)
#adding names to the values in order to match the appropriate mu and dispersion estimates
#to the correct group
names(mu_alt) <- as.list(estimates_group[[k]]$group)
names(theta_adj_group) <- as.list(estimates_group[[k]]$group)
ind1 <- match(names(groups), names(theta_adj_group))
mu_alt <- mu_alt[ind1]
ind2 <- match(names(groups), names(theta_adj_group))
theta_adj_group <- theta_adj_group[ind2]
#replacing null element with NA
mu_alt <- lapply(mu_alt, function(q) ifelse(is.null(q), NA, q))
theta_adj_group <- lapply(theta_adj_group, function(q) ifelse(is.null(q), NA, q))
#calculating group likelihood values
alt.lik <- list()
for (i in 1:length(groups)){
alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_adj_group[names(groups)[i]][[1]]), error = function(e) NA)
}
#calculating group-wise likelihood
loglik1[k] = do.call("sum", c(alt.lik, na.rm = T))
llr[k] = loglik0[k] - loglik1[k]
pval[k] <- pchisq(-2*(llr[k]), df = 1, lower.tail = FALSE)
theta_null <- theta_common
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_llr = mapply(function(p,q) p - q, disp_ge_null.lik, disp_ge_alt.lik, SIMPLIFY = F)
print(paste("k:", k))
print(paste("Length of disp_ge_llr:", length(disp_ge_llr)))
print(paste("Length of disp_ge_llr_vec[k, ]:", length(disp_ge_llr_vec[k, ])))
disp_ge_llr_vec[k, ] <- do.call("c", disp_ge_llr)
disp_ge_pval <- lapply(disp_ge_llr, function(q) pchisq(-2 * q, df = 1, lower.tail = FALSE))
disp_ge_pval_vec[k, ] <- do.call("c", disp_ge_pval)
#replacing null element with NA
#disp_ge_llr <- lapply(disp_ge_llr, function(q) ifelse(is.null(q), NA, q))
disp_ge_llr_vec[k,] <-  do.call("c", disp_ge_llr)
disp_ge_pval <- lapply(disp_ge_llr, function(q) pchisq(-2*q, df = 1, lower.tail = FALSE))
disp_ge_pval_vec[k,] <-  do.call("c", disp_ge_pval)
mu_global[k] <- mu
theta_global[k] <- theta
theta_group[k,] <- do.call("c", theta_adj_group) #shrunk dispersion values per group
mu_group[k,] <- do.call("c", mu_alt) #mean AR values per group
} else {
mu_global[k] <- NA
theta_global[k] <- NA
loglik0[k] <- NA
loglik1[k] <- NA
llr[k] <- NA
pval[k] <- NA
}
}
#colnames(alpha_group) <- paste0("alpha_group", names(groups))
#colnames(beta_group) <- paste0("beta_group", names(groups))
colnames(mu_group) <- paste0("mu_group", names(groups))
colnames(theta_group) <- paste0("theta_group", names(groups))
#colnames(loglik_group) <- paste0("loglik_group", names(groups))
colnames(disp_ge_llr_vec) <- paste0("disp_ge_llr", names(groups))
colnames(disp_ge_pval_vec) <- paste0("disp_ge_pval", names(groups))
#colnames(mu_group) <- paste0("mu_group", names(groups))
#colnames(llr_var) <- paste0("llr_var", names(groups))
#colnames(pval_var) <- paste0("pval_var", names(groups))
out <- data.frame(cbind(#estimates,
N, tot_gene_mean, AR, log2FC, mu_global, theta_global, mu_group, theta_group,
loglik0, loglik1, llr, pval,
disp_ge_llr_vec, disp_ge_pval_vec))
rownames(out) <- rownames(a1_counts)
out
}
pseudot_change <- allelicSwitch(Cast_B6_a1, Cast_B6_tot, min_cells = 5, metadata = pseudotime,  split.var = "group", estimates = global_shrunk, estimates_group = group_params_list)
a1_counts = Cast_B6_a1
tot_counts = Cast_B6_tot
metadata = pseudotime
split.var = "group"
min_counts = 0
min_cells = 5
estimates = global_shrunk
estimates_group = group_params_list
loglik_group <- alpha_group <- beta_group <- mu_group <- theta_group <- theta_fit <- var_group <- var_null_group <- var_alt_group <- llr_imb <- pval_imb <- llr_oneout_group <- pval_oneout_group <-
llr_imb <- pval_imb <- llr_imb_adj <- pval_imb_adj <- theta_fit_ciupper <- theta_fit_cilower <- chisq_group <- within_ci <-
disp_ge_pval_vec <- disp_ge_llr_vec <- matrix(nrow = len, ncol = length(groups))
len <- dim(a1_counts)[1]
loglik_group <- alpha_group <- beta_group <- mu_group <- theta_group <- theta_fit <- var_group <- var_null_group <- var_alt_group <- llr_imb <- pval_imb <- llr_oneout_group <- pval_oneout_group <-
llr_imb <- pval_imb <- llr_imb_adj <- pval_imb_adj <- theta_fit_ciupper <- theta_fit_cilower <- chisq_group <- within_ci <-
disp_ge_pval_vec <- disp_ge_llr_vec <- matrix(nrow = len, ncol = length(groups))
groups <- split(metadata, f = metadata[,colnames(metadata) == split.var])
y <-  a1_counts[k,]
k = 1
y <-  a1_counts[k,]
n <- tot_counts[k,]
a2 <- n - y
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
log2FC[k] = log2(mean(y)) - log2(mean(a2))
df_split <- lapply(groups, function(q) df[rownames(df) %in% rownames(q),])
mu <- estimates[k, "bb_mu"]
theta <- estimates[k, "bb_theta"]
theta_adj <- estimates[k, "thetaCorrected"]
theta_common <- estimates[k, "theta_common"]
nul.lik <- tryCatch(lbetabin(df, mu = mu, theta = theta_adj), error=function(e) NA)
loglik0[k] = nul.lik
mu_alt <- as.list(estimates_group[[k]]$bb_mu)
theta_adj_group <- as.list(estimates_group[[k]]$thetaCorrected)
View(mu_alt)
names(mu_alt) <- as.list(estimates_group[[k]]$group)
names(theta_adj_group) <- as.list(estimates_group[[k]]$group)
ind1 <- match(names(groups), names(theta_adj_group))
mu_alt <- mu_alt[ind1]
ind2 <- match(names(groups), names(theta_adj_group))
theta_adj_group <- theta_adj_group[ind2]
View(theta_adj_group)
#replacing null element with NA
mu_alt <- lapply(mu_alt, function(q) ifelse(is.null(q), NA, q))
theta_adj_group <- lapply(theta_adj_group, function(q) ifelse(is.null(q), NA, q))
#calculating group likelihood values
alt.lik <- list()
for (i in 1:length(groups)){
alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_adj_group[names(groups)[i]][[1]]), error = function(e) NA)
}
theta_null <- theta_common
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_llr = mapply(function(p,q) p - q, disp_ge_null.lik, disp_ge_alt.lik, SIMPLIFY = F)
#replacing null element with NA
#disp_ge_llr <- lapply(disp_ge_llr, function(q) ifelse(is.null(q), NA, q))
disp_ge_llr_vec[k,] <-  do.call("c", disp_ge_llr)
disp_ge_llr
theta_null
disp_ge_null.lik
disp_ge_alt.lik
View(df_split)
View(df)
a1_counts <- as.matrix(a1_counts)
mode(a1_counts) <- "integer"
#a1_sub <- a1_counts[rownames(a1_counts) %in% rownames(estimates),]
tot_counts <- as.matrix(tot_counts)
mode(tot_counts) <- "integer"
mu_alt
theta_alt
theta_alt <- as.list(estimates_group[[k]]$bb_theta)
names(theta_alt) <- as.list(estimates_group[[k]]$group)
ind3 <- match(names(groups), names(mean_alt))
mean_alt <- as.list(estimates_group[[k]]$mean_smoothed)
#adding names to control for the missing values
names(mean_alt) <- as.list(estimates_group[[k]]$group)
theta_alt <- as.list(estimates_group[[k]]$bb_theta)
names(theta_alt) <- as.list(estimates_group[[k]]$group)
ind3 <- match(names(groups), names(mean_alt))
mean_alt <- mean_alt[ind3]
ind4 <- match(names(groups), names(theta_alt))
theta_alt <- theta_alt[ind4]
theta_alt
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
y <-  a1_counts[k,]
n <- tot_counts[k,]
a2 <- n - y
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
View(df)
df_split <- lapply(groups, function(q) df[rownames(df) %in% rownames(q),])
View(df_split)
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_alt.lik
mu_alt
theta_alt
disp_ge_alt.lik
lbetabin <- function(df, inits){
y <- df[,1]
n <- df[,2]
alpha = inits[1]
beta = inits[2]
sum(lchoose(n, y) + lgamma(alpha+beta) - lgamma(n+alpha+beta) +
lgamma(y+alpha) - lgamma(alpha) + lgamma(n-y+beta) - lgamma(beta))
}
#beta-binomial log likelihood function
lbetabin <- function(df, mu, theta){
min_theta = 1e-06
max_mu = 0.999999
min_mu = 1e-06
theta <- pmax(theta, min_theta)
mu <- pmin(mu, max_mu)
mu <- pmax(mu, min_mu)
y <- df[,1]
n <- df[,2]
alpha <- mu/theta
beta <- (1-mu)/theta
sum(lchoose(n, y) + lgamma(alpha+beta) - lgamma(n+alpha+beta) +
lgamma(y+alpha) - lgamma(alpha) + lgamma(n-y+beta) - lgamma(beta))
}
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_llr = mapply(function(p,q) p - q, disp_ge_null.lik, disp_ge_alt.lik, SIMPLIFY = F)
#replacing null element with NA
#disp_ge_llr <- lapply(disp_ge_llr, function(q) ifelse(is.null(q), NA, q))
disp_ge_llr
disp_ge_llr_vec[k,] <-  do.call("c", disp_ge_llr)
do.call("c", disp_ge_llr)
dim(disp_ge_llr_vec)
allelicSwitch <- function(a1_counts, tot_counts, metadata, split.var = "group", min_counts = 0, min_cells = 5, estimates, estimates_group){
are_equal(dim(a1_counts), dim(tot_counts),
msg = paste("allele 1 and total counts matrices must be equal"))
are_equal(rownames(a1_counts), rownames(tot_counts),
msg = paste("allele 1 and total counts matrices must be in the same order"))
are_equal(rownames(a1_counts), rownames(estimates),
msg = paste("gene order in the count matrices and the parameter estimates must be the same"))
are_equal(rownames(estimates), names(estimates_group),
msg = paste("gene order in the global and group parameter estimates must be the same"))
#beta-binomial log likelihood function
lbetabin <- function(df, mu, theta){
min_theta = 1e-06
max_mu = 0.999999
min_mu = 1e-06
theta <- pmax(theta, min_theta)
mu <- pmin(mu, max_mu)
mu <- pmax(mu, min_mu)
y <- df[,1]
n <- df[,2]
alpha <- mu/theta
beta <- (1-mu)/theta
sum(lchoose(n, y) + lgamma(alpha+beta) - lgamma(n+alpha+beta) +
lgamma(y+alpha) - lgamma(alpha) + lgamma(n-y+beta) - lgamma(beta))
}
# A function to rbind the data frames in the list, leaving out one at a time
rbind_consec <- function(df_list, idx) {
df_to_rbind <- df_list[-idx]  # Leave out the data frame at the specified index
do.call(rbind, df_to_rbind)  # Use do.call to rbind all data frames in the list
}
a1_counts <- as.matrix(a1_counts)
mode(a1_counts) <- "integer"
#a1_sub <- a1_counts[rownames(a1_counts) %in% rownames(estimates),]
tot_counts <- as.matrix(tot_counts)
mode(tot_counts) <- "integer"
#tot_sub <- tot_counts[rownames(tot_counts) %in% rownames(estimates),]
groups <- split(metadata, f = metadata[,colnames(metadata) == split.var])
len <- dim(a1_counts)[1]
alpha <- beta <- loglik0  <- loglik1 <- llr <- pval <- loglik0_adj <- loglik1_adj <- llr_adj <- pval_adj <- AR <-  log2FC <- N <- tot_gene_mean <- mu <- var <-
loglik0_var <- loglik1_var <- llr_var <- pval_var <- theta_global <- mu_global <- numeric(len)
loglik_group <- alpha_group <- beta_group <- mu_group <- theta_group <- theta_fit <- var_group <- var_null_group <- var_alt_group <- llr_imb <- pval_imb <- llr_oneout_group <- pval_oneout_group <-
llr_imb <- pval_imb <- llr_imb_adj <- pval_imb_adj <- theta_fit_ciupper <- theta_fit_cilower <- chisq_group <- within_ci <-
disp_ge_pval_vec <- disp_ge_llr_vec <- matrix(nrow = len, ncol = length(groups))
for  (k in 1:nrow(a1_counts)) {
y <-  a1_counts[k,]
n <- tot_counts[k,]
a2 <- n - y
df <- data.frame(y = y, n = n)
df <- na.omit(df)
df <- df[df$n >= min_counts,]
log2FC[k] = log2(mean(y)) - log2(mean(a2))
AR[k] = mean(y/n, na.rm = T)
N[k] = dim(df[df$n >= 5,])[1]
tot_gene_mean[k] = mean(df$n)
if (N[k] >= min_cells){
df_split <- lapply(groups, function(q) df[rownames(df) %in% rownames(q),])
mu <- estimates[k, "bb_mu"]
theta <- estimates[k, "bb_theta"]
theta_adj <- estimates[k, "thetaCorrected"]
theta_common <- estimates[k, "theta_common"]
#########################################
# Test for changes in mean AR over time #
#########################################
#Null hypothesis: assumes no changes between time points
#bb_mu is common mean AR (estimated across cells)
#bb_theta is shrunk theta (across all cells)
nul.lik <- tryCatch(lbetabin(df, mu = mu, theta = theta_adj), error=function(e) NA)
loglik0[k] = nul.lik
#Alternative hypothesis
#bb_mu is mean AR estimated separately for each time point
#bb_theta is shrunk theta in each time point
mu_alt <- as.list(estimates_group[[k]]$bb_mu)
theta_adj_group <- as.list(estimates_group[[k]]$thetaCorrected)
#adding names to the values in order to match the appropriate mu and dispersion estimates
#to the correct group
names(mu_alt) <- as.list(estimates_group[[k]]$group)
names(theta_adj_group) <- as.list(estimates_group[[k]]$group)
ind1 <- match(names(groups), names(theta_adj_group))
mu_alt <- mu_alt[ind1]
ind2 <- match(names(groups), names(theta_adj_group))
theta_adj_group <- theta_adj_group[ind2]
#replacing null element with NA
mu_alt <- lapply(mu_alt, function(q) ifelse(is.null(q), NA, q))
theta_adj_group <- lapply(theta_adj_group, function(q) ifelse(is.null(q), NA, q))
#calculating group likelihood values
alt.lik <- list()
for (i in 1:length(groups)){
alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_adj_group[names(groups)[i]][[1]]), error = function(e) NA)
}
#calculating group-wise likelihood
loglik1[k] = do.call("sum", c(alt.lik, na.rm = T))
llr[k] = loglik0[k] - loglik1[k]
pval[k] <- pchisq(-2*(llr[k]), df = 1, lower.tail = FALSE)
#test for mean equality between the groups whilst keeping theta constant
#to identify changes in the allelic ratio that are due to the changes in mean rather than varince
#theta_null <- theta_common
#mean.nul.lik <- tryCatch(lbetabin(df, mu = mu, theta = theta_null), error=function(e) NA)
#loglik0_mean[k] = mean.nul.lik
#Calculating group-wise likelihoods
#theta_group_null <- as.list(estimates_group[[k]]$theta_common)
#adding names to control for the missing values
#names(theta_group_null) <- as.list(estimates_group[[k]]$group)
#ind2 <- match(names(groups), names(theta_group_null))
#theta_group_null <- theta_group_null[ind2]
#calculating group likelihood values
#alt_mean.lik <- list()
#for (i in 1:length(groups)){
#  alt_mean.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
#                                         mu = mu_alt[names(groups)[i]][[1]],
#                                         theta = theta_group_null[names(groups)[i]][[1]]), error = function(e) NA)
#}
#calculating group-wise likelihood
#loglik1_mean[k] = do.call("sum", alt_mean.lik)
#llr_mean[k] = loglik0_mean[k] - loglik1_mean[k]
#pval_mean[k] <- pchisq(-2*(llr_mean[k]), df = 1, lower.tail = FALSE)
#replace null values with NA
#theta_group_null <- lapply(theta_group_null, function (q) ifelse(is.null(q), NA, q))
#names(theta_group_null) <- as.list(estimates_group[[k]]$group)
#theta_fit[k,] <- do.call("c", theta_group_null)
##############################################################################
# Test for variance equality between the groups whilst keeping mean constant #
##############################################################################
#to identify changes in allelic ratio over pseudotime that are due to the variance rather than mean
#allelic ratio is fixed - locfit regression where mean AR is fitted against the total counts
#Null hypothesis:
#bb_mu is a mean predicted from locfit function (fit across all cells)
#bb_theta is the original dispersion estimate
mean_null <- estimates[k, "mean_smoothed"]
var.nul.lik <- tryCatch(lbetabin(df, mu = mean_null, theta = theta), error=function(e) NA)
loglik0_var[k] = var.nul.lik
#Alternative hypothesis:
#bb_mu is mean predicted from the local regression (fit separately for each time point)
#bb_theta is the original dispersion (estimated for each time point)
mean_alt <- as.list(estimates_group[[k]]$mean_smoothed)
#adding names to control for the missing values
names(mean_alt) <- as.list(estimates_group[[k]]$group)
theta_alt <- as.list(estimates_group[[k]]$bb_theta)
names(theta_alt) <- as.list(estimates_group[[k]]$group)
ind3 <- match(names(groups), names(mean_alt))
mean_alt <- mean_alt[ind3]
ind4 <- match(names(groups), names(theta_alt))
theta_alt <- theta_alt[ind4]
#replacing null element with NA
mean_alt <- lapply(mean_alt, function(q) ifelse(is.null(q), NA, q))
theta_alt <- lapply(theta_alt, function(q) ifelse(is.null(q), NA, q))
#calculating group likelihood values
alt_var.lik <- list()
for (i in 1:length(groups)){
alt_var.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mean_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
#calculating group-wise likelihood
loglik1_var[k] = do.call("sum", c(alt_var.lik, na.rm = T))
llr_var[k] = loglik0_var[k] - loglik1_var[k]
pval_var[k] <- pchisq(-2*(llr_var[k]), df = 1, lower.tail = FALSE)
############################################################
# comparing if variance in a specific time point different #
# from the expected for genes with similar expression      #
############################################################
#Null hypothesis:
#bb_mu is mean AR estimated for each time point
#bb_theta is predicted dispersion obtained from the local regression (fit across all cells)
theta_null <- theta_common
disp_ge_null.lik <- list()
for (i in 1:length(groups)){
disp_ge_null.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_null), error = function(e) NA)
}
#Alternative hypothesis
#bb_mu is mean AR estimated for each time point
#bb_theta is original dispersion estimates for each time point
disp_ge_alt.lik <- list()
for (i in 1:length(groups)){
disp_ge_alt.lik[[i]] <- tryCatch(lbetabin(df_split[names(groups)[i]][[1]],
mu = mu_alt[names(groups)[i]][[1]],
theta = theta_alt[names(groups)[i]][[1]]), error = function(e) NA)
}
disp_ge_llr = mapply(function(p,q) p - q, disp_ge_null.lik, disp_ge_alt.lik, SIMPLIFY = F)
#replacing null element with NA
#disp_ge_llr <- lapply(disp_ge_llr, function(q) ifelse(is.null(q), NA, q))
disp_ge_llr_vec[k,] <-  do.call("c", disp_ge_llr)
disp_ge_pval <- lapply(disp_ge_llr, function(q) pchisq(-2*q, df = 1, lower.tail = FALSE))
disp_ge_pval_vec[k,] <-  do.call("c", disp_ge_pval)
mu_global[k] <- mu
theta_global[k] <- theta
theta_group[k,] <- do.call("c", theta_adj_group) #shrunk dispersion values per group
mu_group[k,] <- do.call("c", mu_alt) #mean AR values per group
} else {
mu_global[k] <- NA
theta_global[k] <- NA
loglik0[k] <- NA
loglik1[k] <- NA
llr[k] <- NA
pval[k] <- NA
loglik0_var[k] <- NA
loglik1_var[k] <- NA
llr_var[k] <- NA
pval_var[k] <- NA
}
}
#colnames(alpha_group) <- paste0("alpha_group", names(groups))
#colnames(beta_group) <- paste0("beta_group", names(groups))
colnames(mu_group) <- paste0("mu_group", names(groups))
colnames(theta_group) <- paste0("theta_group", names(groups))
#colnames(loglik_group) <- paste0("loglik_group", names(groups))
colnames(disp_ge_llr_vec) <- paste0("disp_ge_llr", names(groups))
colnames(disp_ge_pval_vec) <- paste0("disp_ge_pval", names(groups))
#colnames(mu_group) <- paste0("mu_group", names(groups))
#colnames(llr_var) <- paste0("llr_var", names(groups))
#colnames(pval_var) <- paste0("pval_var", names(groups))
out <- data.frame(cbind(#estimates,
N, tot_gene_mean, AR, log2FC, mu_global, theta_global, mu_group, theta_group,
loglik0, loglik1, llr, pval,
loglik0_var, loglik1_var, llr_var, pval_var,
disp_ge_llr_vec, disp_ge_pval_vec))
rownames(out) <- rownames(a1_counts)
out
}
pseudot_change <- allelicSwitch(Cast_B6_a1, Cast_B6_tot, min_cells = 5, metadata = pseudotime,  split.var = "group", estimates = global_shrunk, estimates_group = group_params_list)
devtools::document()
rm(list = c("allelicSwitch"))
devtools::document()
are_equal(dim(a1_counts), dim(tot_counts),
msg = paste("allele 1 and total counts matrices must be equal"))
assert_that(are_equal(dim(a1_counts), dim(tot_counts)),
msg = paste("allele 1 and total counts matrices must be equal"))
tot_counts <- tot_counts[-1,]
assert_that(are_equal(dim(a1_counts), dim(tot_counts)),
msg = paste("allele 1 and total counts matrices must be equal"))
are_equal(dim(a1_counts), dim(tot_counts),
msg = paste("allele 1 and total counts matrices must be equal"))
assert_that(are_equal(dim(metadata)[2], dim(tot_counts)[1]),
msg = paste("Number of cells in metadata and the count matrices must be the same"))
devtools::document()
devtools::install()
library(ASPEN)
library(pkgdown)
use_pkgdown_github_pages()
library(usethis)
use_pkgdown_github_pages()
